{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71e7d14",
   "metadata": {},
   "source": [
    "# 수원서베이 2024 EDA + 핵심지표 대시보드 (v2: 코드/라벨 자동 매핑)\n",
    "\n",
    "- `COMMON_VARS`에 **변수코드(SCORE2, MHQ1...)** 또는 **한국어 라벨(수원시정 만족도, 한 주간 삶의 질_평균(100점)...)** 모두 허용\n",
    "- 코드북을 로드하여 **정확 일치 → 부분 포함(contains)** 순으로 매핑\n",
    "- 매핑 결과는 `mapping` 시트로 함께 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaccb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a3bd11",
   "metadata": {},
   "source": [
    "## 0) 로드/설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882d2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (3057, 481)\n",
      "Weight column: ws\n",
      "COMMON_VARS(raw): ['정책 관심도', '수원시정 만족도', '한 주간 삶의 질_평균(100점)', '영역별 행복 정도_평균(100점)', '환경 만족도_평균(100점)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = Path.cwd().parent\n",
    "DATA_XLSX = BASE / \"output\" / \"1. 수원서베이\" / \"suwon_2024_labeled.xlsx\"\n",
    "DATA_CSV = BASE / \"output\" / \"1. 수원서베이\" / \"suwon_2024_labeled.csv\"\n",
    "CODEBOOK_XLSX = BASE / \"data\" / \"internal\" / \"1. 수원서베이\" / \"(HRC250604) 2024년 수원서베이 용역_공개용 데이터\" / \"(HRC250604) 2024년 수원서베이 용역_공개용 데이터_코드북.xlsx\"\n",
    "\n",
    "OUTDIR = BASE / \"eda\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "DASHBOARD_PATH = OUTDIR / \"dashboard.xlsx\"\n",
    "\n",
    "# 데이터 로드\n",
    "if DATA_XLSX.exists():\n",
    "    df = pd.read_excel(DATA_XLSX, sheet_name=\"data_labeled\")\n",
    "elif DATA_CSV.exists():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "else:\n",
    "    raise FileNotFoundError(\"라벨링 데이터 파일이 없습니다. suwon_2024_labeled.xlsx 또는 CSV를 확인하세요.\")\n",
    "\n",
    "print(\"Loaded:\", df.shape)\n",
    "\n",
    "# 코드북 로드 (Variable Name, Variable Label)\n",
    "cb = pd.read_excel(CODEBOOK_XLSX, sheet_name=0, usecols=[\"Variable Name\", \"Variable Label\"]).drop_duplicates()\n",
    "cb = cb.rename(columns={\"Variable Name\":\"var\", \"Variable Label\":\"label\"})\n",
    "cb = cb.dropna(subset=[\"var\", \"label\"])\n",
    "cb[\"var\"] = cb[\"var\"].astype(str)\n",
    "cb[\"label\"] = cb[\"label\"].astype(str)\n",
    "\n",
    "# 공통 문항 입력\n",
    "common_txt = BASE / \"common_vars.txt\"\n",
    "if common_txt.exists():\n",
    "    with open(common_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "        COMMON_VARS = [line.strip() for line in f if line.strip()]\n",
    "else:\n",
    "    # 예시(라벨 기반)\n",
    "    COMMON_VARS = [\"정책 관심도\", \"수원시정 만족도\", \"한 주간 삶의 질_평균(100점)\", \"영역별 행복 정도_평균(100점)\", \"환경 만족도_평균(100점)\"]\n",
    "\n",
    "# 가중치 선택\n",
    "WEIGHT_COL = \"ws\" if \"ws\" in df.columns else (\"wg\" if \"wg\" in df.columns else None)\n",
    "print(\"Weight column:\", WEIGHT_COL)\n",
    "print(\"COMMON_VARS(raw):\", COMMON_VARS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be5062",
   "metadata": {},
   "source": [
    "## 1) 공통 문항 이름 해석/매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66602f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                input resolved_var      resolved_label       method\n",
      "0              정책 관심도       SCORE1              정책 관심도  label_exact\n",
      "1            수원시정 만족도       SCORE2            수원시정 만족도  label_exact\n",
      "2  한 주간 삶의 질_평균(100점)         MHQ1  한 주간 삶의 질_평균(100점)  label_exact\n",
      "3  영역별 행복 정도_평균(100점)         MHQ2  영역별 행복 정도_평균(100점)  label_exact\n",
      "4     환경 만족도_평균(100점)         MHQ4     환경 만족도_평균(100점)  label_exact\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== 변수명/라벨명 해석기 =====\n",
    "# 1) 사용자가 준 토큰이 df.columns에 이미 있으면 그대로 사용\n",
    "# 2) 코드북 label과 정확히 일치하면 해당 var(code)로\n",
    "# 3) 코드북 label에 부분 포함(contains)되면 가장 긴 일치 라벨을 우선으로 선택\n",
    "# 4) 그래도 실패하면 unresolved로 처리\n",
    "\n",
    "df_cols = set(map(str, df.columns))\n",
    "\n",
    "def resolve_single(token: str):\n",
    "    t = str(token).strip()\n",
    "    # case 1: 이미 컬럼명\n",
    "    if t in df_cols:\n",
    "        # 라벨 찾기\n",
    "        label = cb.loc[cb[\"var\"] == t, \"label\"]\n",
    "        return {\"input\": t, \"resolved_var\": t, \"resolved_label\": (label.iloc[0] if not label.empty else None), \"method\": \"as_is\"}\n",
    "    # case 2: label exact\n",
    "    hit = cb[cb[\"label\"] == t]\n",
    "    if not hit.empty:\n",
    "        v = hit.iloc[0][\"var\"]\n",
    "        if v in df_cols:\n",
    "            return {\"input\": t, \"resolved_var\": v, \"resolved_label\": t, \"method\": \"label_exact\"}\n",
    "    # case 3: label contains\n",
    "    cand = cb[cb[\"label\"].str.contains(t, na=False)]\n",
    "    if not cand.empty:\n",
    "        # 후보 중 df에 존재하는 변수만\n",
    "        cand2 = cand[cand[\"var\"].isin(df_cols)].copy()\n",
    "        if not cand2.empty:\n",
    "            # 가장 긴 라벨(=가장 구체적) 우선\n",
    "            cand2[\"label_len\"] = cand2[\"label\"].str.len()\n",
    "            row = cand2.sort_values(\"label_len\", ascending=False).iloc[0]\n",
    "            return {\"input\": t, \"resolved_var\": row[\"var\"], \"resolved_label\": row[\"label\"], \"method\": \"label_contains\"}\n",
    "    # 실패\n",
    "    return {\"input\": t, \"resolved_var\": None, \"resolved_label\": None, \"method\": \"unresolved\"}\n",
    "\n",
    "resolved = [resolve_single(x) for x in COMMON_VARS]\n",
    "mapping_df = pd.DataFrame(resolved)\n",
    "print(mapping_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f5231",
   "metadata": {},
   "source": [
    "## 2) 보조 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f78994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LIKERT_KEYWORDS = [\n",
    "    \"전혀\", \"그렇지 않다\", \"보통\", \"그렇다\", \"매우\", \"만족\", \"불만족\", \"동의\", \"비동의\",\n",
    "    \"낮다\", \"높다\", \"나쁘다\", \"좋다\", \"의견\", \"정도\", \"점수\", \"만큼\"\n",
    "]\n",
    "\n",
    "def looks_like_likert(series, sample_k=30):\n",
    "    vals = series.dropna().astype(str).unique()[:sample_k]\n",
    "    hit = 0\n",
    "    for v in vals:\n",
    "        if any(k in v for k in LIKERT_KEYWORDS):\n",
    "            hit += 1\n",
    "    nunique = series.nunique(dropna=True)\n",
    "    return (4 <= nunique <= 7) and (hit >= max(1, int(np.ceil(len(vals) * 0.2))))\n",
    "\n",
    "def infer_var_type(s, cat_threshold=0.05, max_cat_unique=30):\n",
    "    s_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "    numeric_ratio = s_num.notna().mean()\n",
    "    nunique = s.nunique(dropna=True)\n",
    "    if numeric_ratio > 0.98:\n",
    "        return \"numeric\"\n",
    "    if looks_like_likert(s):\n",
    "        return \"ordinal_likert\"\n",
    "    if nunique <= max_cat_unique or nunique / max(1, len(s)) <= cat_threshold:\n",
    "        return \"categorical\"\n",
    "    return \"categorical\"\n",
    "\n",
    "def summarize_numeric(s):\n",
    "    s_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return {\n",
    "        \"count\": int(s_num.count()),\n",
    "        \"mean\": float(s_num.mean()) if s_num.count() else np.nan,\n",
    "        \"std\": float(s_num.std()) if s_num.count() else np.nan,\n",
    "        \"min\": float(s_num.min()) if s_num.count() else np.nan,\n",
    "        \"q25\": float(s_num.quantile(0.25)) if s_num.count() else np.nan,\n",
    "        \"median\": float(s_num.median()) if s_num.count() else np.nan,\n",
    "        \"q75\": float(s_num.quantile(0.75)) if s_num.count() else np.nan,\n",
    "        \"max\": float(s_num.max()) if s_num.count() else np.nan,\n",
    "        \"nunique\": int(s_num.nunique(dropna=True)),\n",
    "        \"na_rate\": float(s.isna().mean())\n",
    "    }\n",
    "\n",
    "def weighted_mean(x, w):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    m = ~x.isna() & ~w.isna()\n",
    "    if m.sum() == 0:\n",
    "        return np.nan\n",
    "    return float((x[m] * w[m]).sum() / w[m].sum())\n",
    "\n",
    "def weighted_std(x, w):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    m = ~x.isna() & ~w.isna()\n",
    "    if m.sum() < 2:\n",
    "        return np.nan\n",
    "    mu = (x[m] * w[m]).sum() / w[m].sum()\n",
    "    var = ((w[m] * (x[m] - mu) ** 2).sum()) / (w[m].sum())\n",
    "    return float(np.sqrt(var))\n",
    "\n",
    "def numeric_stats(s, w=None):\n",
    "    base = summarize_numeric(s)\n",
    "    if w is not None:\n",
    "        wm = weighted_mean(s, w)\n",
    "        ws = weighted_std(s, w)\n",
    "        base.update({\"w_mean\": wm, \"w_std\": ws})\n",
    "    return base\n",
    "\n",
    "def categorical_freq(s, w=None):\n",
    "    s2 = s.fillna(\"(결측)\").astype(str)\n",
    "    if w is None:\n",
    "        vc = s2.value_counts(dropna=False).rename(\"count\").to_frame()\n",
    "        vc[\"ratio\"] = vc[\"count\"] / len(s2)\n",
    "        vc = vc.reset_index().rename(columns={\"index\":\"value\"})\n",
    "        return vc[[\"value\", \"ratio\", \"count\"]]\n",
    "    else:\n",
    "        tmp = pd.DataFrame({\"v\": s2, \"w\": w})\n",
    "        grp = tmp.groupby(\"v\", dropna=False, as_index=False)[\"w\"].sum()\n",
    "        total = grp[\"w\"].sum()\n",
    "        grp = grp.rename(columns={\"w\": \"weight\"}).sort_values(\"weight\", ascending=False)\n",
    "        grp[\"ratio\"] = grp[\"weight\"] / total if total > 0 else np.nan\n",
    "        grp = grp.rename(columns={\"v\": \"value\"})\n",
    "        grp[\"count\"] = np.nan\n",
    "        return grp[[\"value\", \"ratio\", \"count\", \"weight\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af032479",
   "metadata": {},
   "source": [
    "## 3) 대시보드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9dddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard saved to: d:\\workspace\\dacon_sri\\eda\\dashboard.xlsx\n",
      "Resolved OK: 5  / Input: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 실제 대시보드 빌드\n",
    "resolved_ok = mapping_df[mapping_df[\"resolved_var\"].notna()].copy()\n",
    "resolved_ok = resolved_ok[resolved_ok[\"resolved_var\"].isin(df.columns)]\n",
    "unresolved = mapping_df[mapping_df[\"resolved_var\"].isna()].copy()\n",
    "\n",
    "w = None\n",
    "if WEIGHT_COL and WEIGHT_COL in df.columns:\n",
    "    w = pd.to_numeric(df[WEIGHT_COL], errors=\"coerce\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "with pd.ExcelWriter(DASHBOARD_PATH, engine=\"xlsxwriter\") as writer:\n",
    "    # mapping 시트\n",
    "    mapping_df.to_excel(writer, sheet_name=\"mapping\", index=False)\n",
    "    # unresolved 시트\n",
    "    if not unresolved.empty:\n",
    "        unresolved.to_excel(writer, sheet_name=\"unresolved\", index=False)\n",
    "\n",
    "    # 변수별 시트 + summary\n",
    "    for _, row in resolved_ok.iterrows():\n",
    "        var = row[\"resolved_var\"]\n",
    "        label = row[\"resolved_label\"]\n",
    "        s = df[var]\n",
    "        vtype = infer_var_type(s)\n",
    "        sheet = (label if isinstance(label, str) and label.strip() else var)[:31]\n",
    "\n",
    "        if vtype == \"numeric\":\n",
    "            stats = numeric_stats(s, w)\n",
    "            stats.update({\"variable\": var, \"label\": label, \"type\":\"numeric\", \"weight\": WEIGHT_COL})\n",
    "            pd.DataFrame([stats]).to_excel(writer, sheet_name=sheet, index=False)\n",
    "            summary_rows.append(stats)\n",
    "        else:\n",
    "            freq = categorical_freq(s, w)\n",
    "            freq.to_excel(writer, sheet_name=sheet, index=False)\n",
    "            # summary top1\n",
    "            top_val = None; top_ratio = np.nan\n",
    "            if not freq.empty:\n",
    "                top_val = freq.iloc[0][\"value\"]\n",
    "                top_ratio = float(freq.iloc[0][\"ratio\"]) if pd.notna(freq.iloc[0][\"ratio\"]) else np.nan\n",
    "            summary_rows.append({\n",
    "                \"variable\": var,\n",
    "                \"label\": label,\n",
    "                \"type\": \"categorical\",\n",
    "                \"top1_value\": top_val,\n",
    "                \"top1_ratio\": top_ratio,\n",
    "                \"nunique\": int(s.nunique(dropna=True)),\n",
    "                \"weight\": WEIGHT_COL\n",
    "            })\n",
    "\n",
    "    if summary_rows:\n",
    "        pd.DataFrame(summary_rows).to_excel(writer, sheet_name=\"summary\", index=False)\n",
    "\n",
    "print(\"Dashboard saved to:\", DASHBOARD_PATH)\n",
    "print(\"Resolved OK:\", len(resolved_ok), \" / Input:\", len(mapping_df))\n",
    "if len(unresolved) > 0:\n",
    "    print(\"[WARN] Unresolved inputs:\", list(unresolved[\"input\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
